{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import signal\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_selection import SelectFdr, chi2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from utils.svm import preProcess, evaluate_set\n",
    "from utils.visualize import showMe\n",
    "from utils.augment import apply_augment\n",
    "from config.default import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(X):\n",
    "    y = []\n",
    "    for i, r in enumerate(X):\n",
    "        l = np.ones(X[r].shape[0])*i\n",
    "        y = y + l.tolist()\n",
    "    y = np.array(y)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for train for class Chew\n",
      "No data available for train for class Chew\n",
      "No data available for train for class Chew\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "39 sessions loaded for training\n",
      "19 sessions loaded for validation\n"
     ]
    }
   ],
   "source": [
    "root_path = 'C:/resources/EMG/'\n",
    "post_fix = '_1s_cleaned' #'_1s_new' #\n",
    "classes = settings['classes']\n",
    "\n",
    "\n",
    "sessions_to_val = ['session_4'] # ['session_1','session_2','session_3','session_4']    #[] # \n",
    "subject_to_val = ['S001',  'S105']\n",
    "\n",
    "# use session4 for validation\n",
    "train_sessions = []\n",
    "val_sessions = []\n",
    "\n",
    "for subject in os.listdir(root_path):\n",
    "        for session in os.listdir(os.path.join(root_path,subject)):\n",
    "            if session in sessions_to_val or subject in subject_to_val:\n",
    "                val_sessions.append(os.path.join(root_path,subject, session))\n",
    "            else:\n",
    "                train_sessions.append(os.path.join(root_path,subject, session))\n",
    "    \n",
    "\n",
    "\n",
    "train_records = {}\n",
    "for c in classes:\n",
    "    class_data = []\n",
    "    for session in train_sessions:\n",
    "        data = np.load(os.path.join(session,c+post_fix+'.npy'),allow_pickle=True)\n",
    "        if data.shape[0] != 0:\n",
    "            class_data.append(data)\n",
    "        else:\n",
    "            print(f\"No data available for train for class {c}\")\n",
    "    \n",
    "    train_records[c] = np.concatenate(class_data)\n",
    "print(f\"{len(train_sessions)} sessions loaded for training\")\n",
    "\n",
    "\n",
    "val_records = {}\n",
    "for c in classes:\n",
    "    class_data = []\n",
    "    for session in val_sessions:\n",
    "        data = np.load(os.path.join(session,c+post_fix+'.npy'),allow_pickle=True)\n",
    "        if data.shape[0] != 0:\n",
    "            class_data.append(data)\n",
    "    if len(class_data) != 0:\n",
    "        val_records[c] = np.concatenate(class_data)\n",
    "    else:\n",
    "        print(f\"No data available for validation for class {c}\")\n",
    "\n",
    "print(f\"{len(val_sessions)} sessions loaded for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(6315, 4, 500)\n",
      "(6315,)\n",
      "Validation:\n",
      "(3033, 4, 500)\n",
      "(3033,)\n"
     ]
    }
   ],
   "source": [
    "n_channels = train_records[\"Rest\"].shape[1]\n",
    "input_length = train_records[\"Rest\"].shape[2]\n",
    "\n",
    "\n",
    "print('Train')\n",
    "train_y = create_labels(train_records)\n",
    "train_X = np.concatenate((list(train_records.values())), axis=0)\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "\n",
    "print('Validation:')\n",
    "val_y = create_labels(val_records)\n",
    "val_X = np.concatenate((list(val_records.values())), axis=0)\n",
    "print(val_X.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After augmentation\n",
      "(18945, 4, 500)\n",
      "(18945,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = apply_augment(train_X, train_y)\n",
    "print(\"After augmentation\")\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18945, 2000)\n",
      "(3033, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Reshape to SVM\n",
    "train_X = train_X.reshape(train_X.shape[0], n_channels*input_length)\n",
    "val_X = val_X.reshape(val_X.shape[0], n_channels*input_length)\n",
    "print(train_X.shape)\n",
    "print(val_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMALLER C -> better fit\n",
    "# HIGHER gamma -> better fit\n",
    "#param_grid = {'C': [1, 10, 100,1000], 'gamma': [1,0.1,0.01,0.001,0.0001]} #acc 88 test acc 45\n",
    "#param_grid = {'C': [100,1000], 'gamma': [0.01,0.001,0.0001]} #slow\n",
    "\n",
    "#param_grid = {'C': [100000,1000000], 'gamma': [0.000001,0.0000001]} \n",
    "param_grid = {'C': [10], 'gamma': [0.01]}\n",
    "#param_grid = {'C': [1, 10,100], 'gamma': [0,1, 0.01,0.001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  51.4s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  51.9s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  52.4s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  57.8s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time= 1.1min\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "models = []\n",
    "def grid(X_train,y_train, X_test, y_test):\n",
    "    grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "    grid.fit(X_train,y_train)\n",
    "    return grid.best_estimator_\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.33, random_state=42)\n",
    "\n",
    "model = grid(X_train,y_train, X_test, y_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb05f8a1e544819bfe507c472bc60dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global accuracy: 98.77%\n",
      "           Accuracy\n",
      "Subject            \n",
      "S002      97.000000\n",
      "S004      97.666667\n",
      "S005      99.000000\n",
      "S006      98.666667\n",
      "S007      97.333333\n",
      "S008      99.333333\n",
      "S009      99.000000\n",
      "S010     100.000000\n",
      "S011     100.000000\n",
      "S101      99.666667\n",
      "S102     100.000000\n",
      "S103      99.000000\n",
      "S104      96.333333\n",
      "S106      99.000000\n"
     ]
    }
   ],
   "source": [
    "evaluate_set(model, train_sessions, classes, post_fix, log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da207a8272e84deab7c15603c302f122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global accuracy: 84.26%\n",
      "         Accuracy\n",
      "Subject          \n",
      "S001        84.00\n",
      "S004        67.00\n",
      "S005        82.00\n",
      "S006        78.00\n",
      "S007        82.00\n",
      "S008        85.00\n",
      "S009        92.00\n",
      "S010        85.00\n",
      "S101        92.00\n",
      "S102        90.00\n",
      "S104        93.00\n",
      "S105        85.75\n",
      "S106        76.00\n"
     ]
    }
   ],
   "source": [
    "evaluate_set(model, val_sessions, classes, post_fix, log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/svm_9subj_no_val.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, 'saved_models/svm_9subj_no_val.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a81b55685ebb6380129efe90592a7e4f2f571da2ab32c8bbcf8b970d830ead19"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
