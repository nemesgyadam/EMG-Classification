{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nemes\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Nemes\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Nemes\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Nemes\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import signal\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_selection import SelectFdr, chi2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from utils.svm import preProcess, evaluate_set\n",
    "from utils.visualize import showMe\n",
    "from utils.augment import augment\n",
    "from config.default import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(X):\n",
    "    y = []\n",
    "    for i, r in enumerate(X):\n",
    "        l = np.ones(X[r].shape[0])*i\n",
    "        y = y + l.tolist()\n",
    "    y = np.array(y)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for train for class Chew\n",
      "No data available for train for class Chew\n",
      "No data available for train for class Chew\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "39 sessions loaded for training\n",
      "19 sessions loaded for validation\n"
     ]
    }
   ],
   "source": [
    "root_path = 'C:/resources/EMG/'\n",
    "post_fix = '_1s_cleaned' #'_1s_new' #\n",
    "classes = settings['classes']\n",
    "\n",
    "\n",
    "sessions_to_val = ['session_4'] # ['session_1','session_2','session_3','session_4']    #[] # \n",
    "subject_to_val = ['S001',  'S105']\n",
    "include = ['S002', 'S004', 'S005', 'S006', 'S007', 'S008', 'S009', 'S101', 'S102']   #['S101', 'S102'] #\n",
    "exclude = ['S003']\n",
    "# use session4 for validation\n",
    "train_sessions = []\n",
    "val_sessions = []\n",
    "for subject in os.listdir(root_path):\n",
    "    if subject not in exclude:\n",
    "    #if subject in include:\n",
    "        for session in os.listdir(os.path.join(root_path,subject)):\n",
    "            if session in sessions_to_val or subject in subject_to_val:\n",
    "                val_sessions.append(os.path.join(root_path,subject, session))\n",
    "            else:\n",
    "                train_sessions.append(os.path.join(root_path,subject, session))\n",
    "        #print(f\"{len(os.listdir(os.path.join(root_path,subject)))} session loaded from subject: {subject}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_records = {}\n",
    "if len(train_sessions) > 0:\n",
    "    for c in classes:\n",
    "        class_data = []\n",
    "        for session in train_sessions:\n",
    "            data = np.load(os.path.join(session,c+post_fix+'.npy'),allow_pickle=True)\n",
    "            if data.shape[0] != 0:\n",
    "                class_data.append(data)\n",
    "            else:\n",
    "                print(f\"No data available for train for class {c}\")\n",
    "        \n",
    "        train_records[c] = np.concatenate(class_data)\n",
    "    print(f\"{len(train_sessions)} sessions loaded for training\")\n",
    "else:\n",
    "    print(\"No train session available\")\n",
    "\n",
    "val_records = {}\n",
    "for c in classes:\n",
    "    class_data = []\n",
    "    for session in val_sessions:\n",
    "        data = np.load(os.path.join(session,c+post_fix+'.npy'),allow_pickle=True)\n",
    "        if data.shape[0] != 0:\n",
    "            class_data.append(data)\n",
    "    if len(class_data) != 0:\n",
    "        val_records[c] = np.concatenate(class_data)\n",
    "    else:\n",
    "        print(f\"No data available for validation for class {c}\")\n",
    "\n",
    "print(f\"{len(val_sessions)} sessions loaded for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET\n",
      "Rest -> (1635, 4, 500)\n",
      "Eyebrow -> (2292, 4, 500)\n",
      "Chew -> (1452, 4, 500)\n",
      "Smile -> (936, 4, 500)\n",
      "VAL SET\n",
      "Rest -> (654, 4, 500)\n",
      "Eyebrow -> (1107, 4, 500)\n",
      "Chew -> (708, 4, 500)\n",
      "Smile -> (564, 4, 500)\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN SET\")\n",
    "for r in train_records:\n",
    "    print(f'{r} -> {train_records[r].shape}')\n",
    "\n",
    "print(\"VAL SET\")\n",
    "for r in val_records:\n",
    "    print(f'{r} -> {val_records[r].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(6315, 4, 500)\n",
      "(6315,)\n",
      "Validation:\n",
      "(3033, 4, 500)\n",
      "(3033,)\n"
     ]
    }
   ],
   "source": [
    "n_channels = train_records[\"Rest\"].shape[1]\n",
    "input_length = train_records[\"Rest\"].shape[2]\n",
    "\n",
    "\n",
    "print('Train')\n",
    "train_y = create_labels(train_records)\n",
    "train_X = np.concatenate((list(train_records.values())), axis=0)\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "\n",
    "print('Validation:')\n",
    "val_y = create_labels(val_records)\n",
    "val_X = np.concatenate((list(val_records.values())), axis=0)\n",
    "print(val_X.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6315, 2000)\n",
      "(3033, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Reshape to SVM\n",
    "train_X = train_X.reshape(train_X.shape[0], n_channels*input_length)\n",
    "val_X = val_X.reshape(val_X.shape[0], n_channels*input_length)\n",
    "print(train_X.shape)\n",
    "print(val_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMALLER C -> better fit\n",
    "# HIGHER gamma -> better fit\n",
    "#param_grid = {'C': [1, 10, 100,1000], 'gamma': [1,0.1,0.01,0.001,0.0001]} #acc 88 test acc 45\n",
    "#param_grid = {'C': [100,1000], 'gamma': [0.01,0.001,0.0001]} #slow\n",
    "\n",
    "#param_grid = {'C': [100000,1000000], 'gamma': [0.000001,0.0000001]} \n",
    "param_grid = {'C': [10], 'gamma': [0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  12.1s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  12.7s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  12.8s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  13.5s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  11.6s\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "models = []\n",
    "def grid(X_train,y_train, X_test, y_test):\n",
    "    grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "    grid.fit(X_train,y_train)\n",
    "\n",
    "    grid_predictions = grid.predict(X_test)\n",
    "    acc = accuracy_score(y_test,grid_predictions)\n",
    "    accs.append(acc)\n",
    "    models.append(grid.best_estimator_)\n",
    "    # if acc > 0.9:\n",
    "    #     return True\n",
    "    # else:\n",
    "    #     return False\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10,random_state= 42, shuffle = True)\n",
    "for train, test in skf.split(train_X, train_y):\n",
    "    \n",
    "    X_train = train_X[train]\n",
    "    y_train = train_y[train]\n",
    "    X_test = train_X[test]\n",
    "    y_test = train_y[test]\n",
    "\n",
    "    grid(X_train,y_train, X_test, y_test)\n",
    "    # if grid(X_train,y_train, X_test, y_test):\n",
    "    #     break\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9113924050632911\n"
     ]
    }
   ],
   "source": [
    "model = models[accs.index(max(accs))]\n",
    "for acc in accs:\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff4773832d54589b67a1a50d02b060e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for class Smile\n",
      "No data for class Smile\n",
      "No data for class Chew\n",
      "No data for class Smile\n",
      "No data for class Smile\n",
      "No data for class Chew\n",
      "No data for class Chew\n",
      "No data for class Smile\n",
      "No data for class Smile\n",
      "No data for class Smile\n",
      "Global accuracy: 97.97%\n",
      "          Accuracy\n",
      "Subject           \n",
      "S002     96.000000\n",
      "S004     94.333333\n",
      "S005     98.333333\n",
      "S006     98.666667\n",
      "S007     95.666667\n",
      "S008     98.666667\n",
      "S009     99.000000\n",
      "S010     99.333333\n",
      "S011     99.500000\n",
      "S101     98.666667\n",
      "S102     99.333333\n",
      "S103     99.333333\n",
      "S104     95.000000\n",
      "S106     99.000000\n"
     ]
    }
   ],
   "source": [
    "evaluate_set(model, train_sessions, classes, post_fix, log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a445146ae3340f2a2e9251702bafc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for class Smile\n",
      "No data for class Chew\n",
      "No data for class Chew\n",
      "No data for class Rest\n",
      "No data for class Chew\n",
      "Global accuracy: 84.16%\n",
      "         Accuracy\n",
      "Subject          \n",
      "S001        86.75\n",
      "S004        66.00\n",
      "S005        85.00\n",
      "S006        81.00\n",
      "S007        83.00\n",
      "S008        84.00\n",
      "S009        88.00\n",
      "S010        89.00\n",
      "S101        92.00\n",
      "S102        92.00\n",
      "S104        93.00\n",
      "S105        81.75\n",
      "S106        72.00\n"
     ]
    }
   ],
   "source": [
    "evaluate_set(model, val_sessions, classes, post_fix, log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/svm_9subj_no_val.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, 'saved_models/svm_9subj_no_val.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a81b55685ebb6380129efe90592a7e4f2f571da2ab32c8bbcf8b970d830ead19"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
