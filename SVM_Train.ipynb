{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import signal\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_selection import SelectFdr, chi2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from utils.svm import preProcess, evaluate_set\n",
    "from utils.visualize import showMe\n",
    "from utils.augment import augment\n",
    "from config.default import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for train for class Chew\n",
      "No data available for train for class Chew\n",
      "No data available for train for class Chew\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "No data available for train for class Smile\n",
      "33 sessions loaded for training\n",
      "No data available for validation for class Rest\n",
      "No data available for validation for class Eyebrow\n",
      "No data available for validation for class Chew\n",
      "No data available for validation for class Smile\n",
      "0 sessions loaded for validation\n"
     ]
    }
   ],
   "source": [
    "root_path = 'C:/resources/EMG/'\n",
    "post_fix = '_1s_cleaned' #'_1s_new' #\n",
    "classes = settings['classes']\n",
    "\n",
    "\n",
    "sessions_to_val = [] #['session_4'] # ['session_1','session_2','session_3','session_4']    #[] # \n",
    "include = ['S002', 'S004', 'S005', 'S006', 'S007', 'S008', 'S009', 'S101', 'S102']   #['S101', 'S102'] #\n",
    "# use session4 for validation\n",
    "train_sessions = []\n",
    "val_sessions = []\n",
    "for subject in os.listdir(root_path):\n",
    "    #if subject not in exclude:\n",
    "    if subject in include:\n",
    "        for session in os.listdir(os.path.join(root_path,subject)):\n",
    "            if session in sessions_to_val:\n",
    "                val_sessions.append(os.path.join(root_path,subject, session))\n",
    "            else:\n",
    "                train_sessions.append(os.path.join(root_path,subject, session))\n",
    "        #print(f\"{len(os.listdir(os.path.join(root_path,subject)))} session loaded from subject: {subject}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_records = {}\n",
    "if len(train_sessions) > 0:\n",
    "    for c in classes:\n",
    "        class_data = []\n",
    "        for session in train_sessions:\n",
    "            data = np.load(os.path.join(session,c+post_fix+'.npy'),allow_pickle=True)\n",
    "            if data.shape[0] != 0:\n",
    "                class_data.append(data)\n",
    "            else:\n",
    "                #val_records[c] = np.random.rand(1, 4, 500)\n",
    "                #print(f'WARNING! CREATING RANDOM DATA FOR {c}')\n",
    "                print(f\"No data available for train for class {c}\")\n",
    "        \n",
    "        train_records[c] = np.concatenate(class_data)\n",
    "    print(f\"{len(train_sessions)} sessions loaded for training\")\n",
    "else:\n",
    "    print(\"No train session available\")\n",
    "\n",
    "val_records = {}\n",
    "for c in classes:\n",
    "    class_data = []\n",
    "    for session in val_sessions:\n",
    "        data = np.load(os.path.join(session,c+post_fix+'.npy'),allow_pickle=True)\n",
    "        if data.shape[0] != 0:\n",
    "            class_data.append(data)\n",
    "    if len(class_data) != 0:\n",
    "        val_records[c] = np.concatenate(class_data)\n",
    "    else:\n",
    "        #val_records[c] = np.random.rand(1, 4, 500)\n",
    "        #print(f'WARNING! CREATING RANDOM DATA FOR {c}')\n",
    "        print(f\"No data available for validation for class {c}\")\n",
    "\n",
    "print(f\"{len(val_sessions)} sessions loaded for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET\n",
      "Rest -> (1515, 4, 500)\n",
      "Eyebrow -> (1887, 4, 500)\n",
      "Chew -> (1281, 4, 500)\n",
      "Smile -> (813, 4, 500)\n",
      "VAL SET\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN SET\")\n",
    "for r in train_records:\n",
    "    print(f'{r} -> {train_records[r].shape}')\n",
    "\n",
    "print(\"VAL SET\")\n",
    "for r in val_records:\n",
    "    print(f'{r} -> {val_records[r].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(X):\n",
    "    y = []\n",
    "    for i, r in enumerate(X):\n",
    "        l = np.ones(X[r].shape[0])*i\n",
    "        y = y + l.tolist()\n",
    "    y = np.array(y)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(5496, 4, 500)\n",
      "(5496,)\n",
      "Validation:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-3428e118f871>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Validation:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mval_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_records\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mval_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_records\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "n_channels = train_records[\"Rest\"].shape[1]\n",
    "input_length = train_records[\"Rest\"].shape[2]\n",
    "\n",
    "\n",
    "print('Train')\n",
    "train_y = create_labels(train_records)\n",
    "train_X = np.concatenate((list(train_records.values())), axis=0)\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "\n",
    "print('Validation:')\n",
    "val_y = create_labels(val_records)\n",
    "val_X = np.concatenate((list(val_records.values())), axis=0)\n",
    "print(val_X.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5496, 2000)\n",
      "(1266, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Reshape to SVM\n",
    "train_X = train_X.reshape(train_X.shape[0], n_channels*input_length)\n",
    "val_X = val_X.reshape(val_X.shape[0], n_channels*input_length)\n",
    "print(train_X.shape)\n",
    "print(val_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5496, 2000)\n",
      "(5496,)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle\n",
    "c = list(zip(train_X, train_y))\n",
    "random.seed(42)\n",
    "random.shuffle(c)\n",
    "train_X, train_y = zip(*c)\n",
    "train_X = np.array(train_X)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes After augmentation\n",
      "(1800, 2000)\n",
      "(1800,)\n"
     ]
    }
   ],
   "source": [
    "X, y = augment(X, y)\n",
    "print(\"Shapes After augmentation\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMALLER C -> better fit\n",
    "# HIGHER gamma -> better fit\n",
    "#param_grid = {'C': [1, 10, 100,1000], 'gamma': [1,0.1,0.01,0.001,0.0001]} #acc 88 test acc 45\n",
    "#param_grid = {'C': [100,1000], 'gamma': [0.01,0.001,0.0001]} #slow\n",
    "\n",
    "#param_grid = {'C': [100000,1000000], 'gamma': [0.000001,0.0000001]} \n",
    "param_grid = {'C': [10], 'gamma': [0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   8.8s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   9.2s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   9.2s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   8.7s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   8.7s\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "models = []\n",
    "def grid(X_train,y_train, X_test, y_test):\n",
    "    grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "    grid.fit(X_train,y_train)\n",
    "\n",
    "    grid_predictions = grid.predict(X_test)\n",
    "    acc = accuracy_score(y_test,grid_predictions)\n",
    "    accs.append(acc)\n",
    "    models.append(grid.best_estimator_)\n",
    "    # if acc > 0.9:\n",
    "    #     return True\n",
    "    # else:\n",
    "    #     return False\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10,random_state= 42, shuffle = True)\n",
    "for train, test in skf.split(train_X, train_y):\n",
    "    \n",
    "    X_train = train_X[train]\n",
    "    y_train = train_y[train]\n",
    "    X_test = train_X[test]\n",
    "    y_test = train_y[test]\n",
    "\n",
    "    grid(X_train,y_train, X_test, y_test)\n",
    "    # if grid(X_train,y_train, X_test, y_test):\n",
    "    #     break\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9418181818181818\n"
     ]
    }
   ],
   "source": [
    "model = models[accs.index(max(accs))]\n",
    "for acc in accs:\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b139812aa5604c0dbbbc3c1b97a72475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for class Smile\n",
      "No data for class Smile\n",
      "No data for class Smile\n",
      "No data for class Chew\n",
      "No data for class Smile\n",
      "No data for class Smile\n",
      "No data for class Chew\n",
      "No data for class Chew\n",
      "No data for class Smile\n",
      "Global accuracy: 98.24%\n",
      "         Accuracy\n",
      "Subject          \n",
      "S002        96.00\n",
      "S004        96.00\n",
      "S005        98.50\n",
      "S006        99.50\n",
      "S007        96.25\n",
      "S008        98.25\n",
      "S009        98.75\n",
      "S101        99.50\n",
      "S102        99.75\n"
     ]
    }
   ],
   "source": [
    "evaluate_set(model, train_sessions, classes, post_fix, log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7858334ee44f7186638a92a8cfdd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for class Smile\n",
      "Global accuracy: 81.88%\n",
      "         Accuracy\n",
      "Subject          \n",
      "S004           65\n",
      "S005           83\n",
      "S006           74\n",
      "S007           82\n",
      "S008           82\n",
      "S009           87\n",
      "S101           91\n",
      "S102           91\n"
     ]
    }
   ],
   "source": [
    "evaluate_set(model, val_sessions, classes, post_fix, log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/svm_9subj_no_val.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, 'saved_models/svm_9subj_no_val.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a81b55685ebb6380129efe90592a7e4f2f571da2ab32c8bbcf8b970d830ead19"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
